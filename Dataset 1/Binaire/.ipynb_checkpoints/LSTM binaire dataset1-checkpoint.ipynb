{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-22T19:26:39.782089Z",
     "iopub.status.busy": "2021-08-22T19:26:39.780853Z",
     "iopub.status.idle": "2021-08-22T19:26:50.799478Z",
     "shell.execute_reply": "2021-08-22T19:26:50.798770Z"
    },
    "papermill": {
     "duration": 11.030007,
     "end_time": "2021-08-22T19:26:50.799657",
     "exception": false,
     "start_time": "2021-08-22T19:26:39.769650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improt time 7.272850513458252\n",
      "creating input data time 0.27448558807373047\n",
      "30497\n",
      "tensor([0, 0, 0,  ..., 0, 1, 0])\n",
      "190988\n",
      "143243\n",
      "143244\n",
      "0.7700693607330322\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import os\n",
    "\n",
    "a=time.time()\n",
    "path0 ='../'\n",
    "df = pd.read_csv(path0+\"Dataset_S022Final.csv\")\n",
    "df=df[['Next_Current_diff','Next_Pre_diff','SNext_Current_diff','SNext_Pre_diff','rcvdPK','duration(ms)','packet_type','droppedPKWrongPort','sentPK','size','channel','DataQueueLen','passedUpPk','rcvdPKFromHL','rcvdPKFromLL','sentDownPK','DropPKByQueue','snir','throughput','label']]         \n",
    "\n",
    "df_Normal=df[0:76064].copy()\n",
    "#print(df_Normal)\n",
    "df_UDP=df[76064:214037].copy()\n",
    "#print(df_UDP)\n",
    "df_pluies=df[214037:426866].copy()\n",
    "#print(df_Normal2)\n",
    "df_jam=df[462481:-1].copy()\n",
    "\n",
    "X=df_Normal.drop(columns = ['label']).copy()\n",
    "y=df_Normal[['label']].copy()\n",
    "X1=df_UDP.drop(columns = ['label']).copy()\n",
    "y1=df_UDP[['label']].copy()\n",
    "X2=df_pluies.drop(columns = ['label']).copy()\n",
    "y2=df_pluies[['label']].copy()\n",
    "X3=df_jam.drop(columns = ['label']).copy()\n",
    "y3=df_jam[['label']].copy()\n",
    "\n",
    "train=0.4\n",
    "xcol=X.columns\n",
    "ycol=y.columns\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=train,shuffle=False)\n",
    "X_train1, X_rem1, y_train1, y_rem1 = train_test_split(X1,y1, train_size=train,shuffle=False)\n",
    "X_train2, X_rem2, y_train2, y_rem2 = train_test_split(X2,y2, train_size=train,shuffle=False)\n",
    "X_train3, X_rem3, y_train3, y_rem3 = train_test_split(X3,y3, train_size=train,shuffle=False)\n",
    "validation=0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5,shuffle=False)\n",
    "X_valid1, X_test1, y_valid1, y_test1 = train_test_split(X_rem1,y_rem1, test_size=0.5,shuffle=False)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_rem2,y_rem2, test_size=0.5,shuffle=False)\n",
    "X_valid3, X_test3, y_valid3, y_test3 = train_test_split(X_rem3,y_rem3, test_size=0.5,shuffle=False)\n",
    "\n",
    "\n",
    "X_train=np.concatenate((X_train, X_train1, X_train2,X_train3))\n",
    "X_valid=np.concatenate((X_valid, X_valid1, X_valid2,X_valid3))\n",
    "X_test=np.concatenate((X_test, X_test1, X_test2,X_test3))\n",
    "\n",
    "y_train=np.concatenate((y_train, y_train1, y_train2,y_train3))\n",
    "y_valid=np.concatenate((y_valid, y_valid1, y_valid2,y_valid3))\n",
    "y_test=np.concatenate((y_test, y_test1, y_test2,y_test3))\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns= xcol)\n",
    "X_valid = pd.DataFrame(X_valid, columns= xcol)\n",
    "X_test = pd.DataFrame(X_test, columns= xcol)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns= ycol)\n",
    "y_valid = pd.DataFrame(y_valid, columns= ycol)\n",
    "y_test = pd.DataFrame(y_test, columns= ycol)\n",
    "#print('creating input data time '+str(time.time()-a))\n",
    "a-time.time()\n",
    "X_train1=X_train.values\n",
    "y_train1=y_train.values\n",
    "#X_train1=X_train1.astype(float)\n",
    "\n",
    "torch_tensor = torch.tensor(X_train1)\n",
    "#torch_tensor[torch_tensor != torch_tensor]=float(0)\n",
    "t=[]\n",
    "test=0\n",
    "test0=0\n",
    "\n",
    "for j in y_train1:\n",
    "    i=j[0]\n",
    "#    print(i)\n",
    "    if (i=='Normal'):\n",
    "        t.append(int(0))\n",
    "        test0+=1\n",
    "    #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        t.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        t.append(int(0))\n",
    "        test+=1\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        t.append(int(1))\n",
    "print(test)\n",
    "labels = torch.LongTensor(t)\n",
    "print(labels)\n",
    "bigX = X_valid\n",
    "bigY = y_valid['label']\n",
    "#print(bigY)\n",
    "X_valid1=bigX.values\n",
    "y_valid1=bigY.values\n",
    "\n",
    "vtorch_tensor = torch.tensor(X_valid1)\n",
    "v=[]\n",
    "\n",
    "for i in y_valid1:\n",
    "    if (i=='Normal'):\n",
    "        v.append(int(0))\n",
    "        #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        v.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        v.append(int(0))\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        v.append(int(1))\n",
    "\n",
    "vlabels = torch.LongTensor(v)\n",
    "X_test1=X_test.values\n",
    "y_test1=y_test.values\n",
    "\n",
    "ttorch_tensor = torch.tensor(X_test1)\n",
    "t=[]\n",
    "\n",
    "for j in y_test1:\n",
    "    i=j[0]\n",
    "    if (i=='Normal'):\n",
    "        t.append(int(0))\n",
    "        #t.append(int(1))\n",
    "    if (i=='DDOS_UDP_FLOOD'):\n",
    "        t.append(int(1))\n",
    "    if (i=='PLUIES_ET_ORAGES'):\n",
    "        t.append(int(0))\n",
    "    if (i=='BROUILLAGE_Trafic'):\n",
    "        t.append(int(1))\n",
    "\n",
    "tlabels = torch.LongTensor(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T19:26:50.834339Z",
     "iopub.status.busy": "2021-08-22T19:26:50.828785Z",
     "iopub.status.idle": "2021-08-22T19:26:50.852353Z",
     "shell.execute_reply": "2021-08-22T19:26:50.851808Z"
    },
    "papermill": {
     "duration": 0.044821,
     "end_time": "2021-08-22T19:26:50.852507",
     "exception": false,
     "start_time": "2021-08-22T19:26:50.807686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_classes = 2\n",
    "#num_epochs = 2\n",
    "learning_rate = 0.02\n",
    "input_size = 19\n",
    "sequence_length = 28\n",
    "hidden_size = 132\n",
    "num_layers = 2\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=x.view(-1,1,19)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        out, _ = self.rnn(x, (h0,c0) )  \n",
    "        out = out[:, -1, :]\n",
    "        x = F.log_softmax(self.fc(out), dim=1)\n",
    "        # out: (n, 10)\n",
    "        return x\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "Fonction_de_perte = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-22T19:26:50.886085Z",
     "iopub.status.busy": "2021-08-22T19:26:50.885285Z",
     "iopub.status.idle": "2021-08-23T00:57:34.475647Z",
     "shell.execute_reply": "2021-08-23T00:57:34.476182Z"
    },
    "papermill": {
     "duration": 19843.61657,
     "end_time": "2021-08-23T00:57:34.476411",
     "exception": false,
     "start_time": "2021-08-22T19:26:50.859841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190988\n",
      "190988\n",
      "Epoch  : valid accuracy :72.44123840 with total prob : 51.70550919 \n",
      "Epoch 0 : Training loss 0.11525129 and valid loss : -0.91431814 :  \n",
      "Epoch 0 : valid accuracy :94.21821594 with total prob : 96.91912842 \n",
      "400.9177906513214\n",
      "validation loss decreased , saving model (inf ==> -0.91431814)\n",
      "Epoch 1 : Training loss 0.00696764 and valid loss : -0.96229669 :  \n",
      "Epoch 1 : valid accuracy :96.66231537 with total prob : 98.65269470 \n",
      "405.59343338012695\n",
      "validation loss decreased , saving model (-0.91431814 ==> -0.96229669)\n",
      "Epoch 2 : Training loss 0.00347876 and valid loss : -0.98169707 :  \n",
      "Epoch 2 : valid accuracy :98.53256226 with total prob : 98.95729065 \n",
      "404.46300768852234\n",
      "validation loss decreased , saving model (-0.96229669 ==> -0.98169707)\n",
      "Epoch 3 : Training loss 0.00250301 and valid loss : -0.99146175 :  \n",
      "Epoch 3 : valid accuracy :99.41847229 with total prob : 99.28127289 \n",
      "401.1475603580475\n",
      "validation loss decreased , saving model (-0.98169707 ==> -0.99146175)\n",
      "Epoch 4 : Training loss 0.00205495 and valid loss : -0.99501867 :  \n",
      "Epoch 4 : valid accuracy :99.69352722 with total prob : 99.56864166 \n",
      "407.73343896865845\n",
      "validation loss decreased , saving model (-0.99146175 ==> -0.99501867)\n",
      "Epoch 5 : Training loss 0.00180638 and valid loss : -0.99590515 :  \n",
      "Epoch 5 : valid accuracy :99.64884949 with total prob : 99.68802643 \n",
      "403.0072772502899\n",
      "validation loss decreased , saving model (-0.99501867 ==> -0.99590515)\n",
      "Epoch 6 : Training loss 0.00164994 and valid loss : -0.99609173 :  \n",
      "Epoch 6 : valid accuracy :99.61393738 with total prob : 99.73182678 \n",
      "403.5752546787262\n",
      "validation loss decreased , saving model (-0.99590515 ==> -0.99609173)\n",
      "Epoch 7 : Training loss 0.00153853 and valid loss : -0.99614135 :  \n",
      "Epoch 7 : valid accuracy :99.59998322 with total prob : 99.75465393 \n",
      "399.6180753707886\n",
      "validation loss decreased , saving model (-0.99609173 ==> -0.99614135)\n",
      "Epoch 8 : Training loss 0.00145132 and valid loss : -0.99617793 :  \n",
      "Epoch 8 : valid accuracy :99.59230042 with total prob : 99.76971436 \n",
      "395.9273681640625\n",
      "validation loss decreased , saving model (-0.99614135 ==> -0.99617793)\n",
      "Epoch 9 : Training loss 0.00137785 and valid loss : -0.99622968 :  \n",
      "Epoch 9 : valid accuracy :99.59159851 with total prob : 99.78083038 \n",
      "396.8398790359497\n",
      "validation loss decreased , saving model (-0.99617793 ==> -0.99622968)\n",
      "Epoch 10 : Training loss 0.00131242 and valid loss : -0.99630353 :  \n",
      "Epoch 10 : valid accuracy :99.59369659 with total prob : 99.78941345 \n",
      "396.76021671295166\n",
      "validation loss decreased , saving model (-0.99622968 ==> -0.99630353)\n",
      "Epoch 11 : Training loss 0.00125186 and valid loss : -0.99640156 :  \n",
      "Epoch 11 : valid accuracy :99.60346985 with total prob : 99.79606628 \n",
      "397.6018433570862\n",
      "validation loss decreased , saving model (-0.99630353 ==> -0.99640156)\n",
      "Epoch 12 : Training loss 0.00119433 and valid loss : -0.99652520 :  \n",
      "Epoch 12 : valid accuracy :99.61534119 with total prob : 99.80096436 \n",
      "398.4396884441376\n",
      "validation loss decreased , saving model (-0.99640156 ==> -0.99652520)\n",
      "Epoch 13 : Training loss 0.00113875 and valid loss : -0.99667622 :  \n",
      "Epoch 13 : valid accuracy :99.63977051 with total prob : 99.80451202 \n",
      "395.6076843738556\n",
      "validation loss decreased , saving model (-0.99652520 ==> -0.99667622)\n",
      "Epoch 14 : Training loss 0.00108440 and valid loss : -0.99685643 :  \n",
      "Epoch 14 : valid accuracy :99.66979218 with total prob : 99.80711365 \n",
      "397.60649847984314\n",
      "validation loss decreased , saving model (-0.99667622 ==> -0.99685643)\n",
      "Epoch 15 : Training loss 0.00103080 and valid loss : -0.99706656 :  \n",
      "Epoch 15 : valid accuracy :99.70609283 with total prob : 99.81024170 \n",
      "393.5588843822479\n",
      "validation loss decreased , saving model (-0.99685643 ==> -0.99706656)\n",
      "Epoch 16 : Training loss 0.00097761 and valid loss : -0.99730449 :  \n",
      "Epoch 16 : valid accuracy :99.72633362 with total prob : 99.81290436 \n",
      "392.5344750881195\n",
      "validation loss decreased , saving model (-0.99706656 ==> -0.99730449)\n",
      "Epoch 17 : Training loss 0.00092473 and valid loss : -0.99756362 :  \n",
      "Epoch 17 : valid accuracy :99.75705719 with total prob : 99.81506348 \n",
      "392.12383341789246\n",
      "validation loss decreased , saving model (-0.99730449 ==> -0.99756362)\n",
      "Epoch 18 : Training loss 0.00087240 and valid loss : -0.99783247 :  \n",
      "Epoch 18 : valid accuracy :99.82617188 with total prob : 99.82075500 \n",
      "395.6229102611542\n",
      "validation loss decreased , saving model (-0.99756362 ==> -0.99783247)\n",
      "Epoch 19 : Training loss 0.00082129 and valid loss : -0.99809659 :  \n",
      "Epoch 19 : valid accuracy :99.88341522 with total prob : 99.83158112 \n",
      "395.11797428131104\n",
      "validation loss decreased , saving model (-0.99783247 ==> -0.99809659)\n",
      "Epoch 20 : Training loss 0.00077245 and valid loss : -0.99834211 :  \n",
      "Epoch 20 : valid accuracy :99.94065857 with total prob : 99.84712982 \n",
      "390.0376989841461\n",
      "validation loss decreased , saving model (-0.99809659 ==> -0.99834211)\n",
      "Epoch 21 : Training loss 0.00072697 and valid loss : -0.99855917 :  \n",
      "Epoch 21 : valid accuracy :99.96299744 with total prob : 99.86334229 \n",
      "390.1642949581146\n",
      "validation loss decreased , saving model (-0.99834211 ==> -0.99855917)\n",
      "Epoch 22 : Training loss 0.00068511 and valid loss : -0.99874363 :  \n",
      "Epoch 22 : valid accuracy :99.97207642 with total prob : 99.87813568 \n",
      "393.2088463306427\n",
      "validation loss decreased , saving model (-0.99855917 ==> -0.99874363)\n",
      "Epoch 23 : Training loss 0.00064587 and valid loss : -0.99889672 :  \n",
      "Epoch 23 : valid accuracy :99.98533630 with total prob : 99.89148712 \n",
      "393.91237688064575\n",
      "validation loss decreased , saving model (-0.99874363 ==> -0.99889672)\n",
      "Epoch 24 : Training loss 0.00060817 and valid loss : -0.99902277 :  \n",
      "Epoch 24 : valid accuracy :99.99510956 with total prob : 99.90319824 \n",
      "393.00949811935425\n",
      "validation loss decreased , saving model (-0.99889672 ==> -0.99902277)\n",
      "Epoch 25 : Training loss 0.00057329 and valid loss : -0.99912667 :  \n",
      "Epoch 25 : valid accuracy :99.99650574 with total prob : 99.91328430 \n",
      "396.12546396255493\n",
      "validation loss decreased , saving model (-0.99902277 ==> -0.99912667)\n",
      "Epoch 26 : Training loss 0.00054033 and valid loss : -0.99921261 :  \n",
      "Epoch 26 : valid accuracy :99.99720764 with total prob : 99.92165375 \n",
      "394.7884120941162\n",
      "validation loss decreased , saving model (-0.99912667 ==> -0.99921261)\n",
      "Epoch 27 : Training loss 0.00049571 and valid loss : -0.99928377 :  \n",
      "Epoch 27 : valid accuracy :99.99720764 with total prob : 99.92859650 \n",
      "396.0439989566803\n",
      "validation loss decreased , saving model (-0.99921261 ==> -0.99928377)\n",
      "Epoch 28 : Training loss 0.00049722 and valid loss : -0.99934454 :  \n",
      "Epoch 28 : valid accuracy :99.99720764 with total prob : 99.93453217 \n",
      "397.1109149456024\n",
      "validation loss decreased , saving model (-0.99928377 ==> -0.99934454)\n",
      "Epoch 29 : Training loss 0.00027168 and valid loss : -0.99940768 :  \n",
      "Epoch 29 : valid accuracy :99.99930573 with total prob : 99.94077301 \n",
      "393.39509868621826\n",
      "validation loss decreased , saving model (-0.99934454 ==> -0.99940768)\n",
      "Epoch 30 : Training loss 0.00024234 and valid loss : -0.99946021 :  \n",
      "Epoch 30 : valid accuracy :100.00000000 with total prob : 99.94602966 \n",
      "396.28285479545593\n",
      "validation loss decreased , saving model (-0.99940768 ==> -0.99946021)\n",
      "Epoch 31 : Training loss 0.00021881 and valid loss : -0.99950414 :  \n",
      "Epoch 31 : valid accuracy :100.00000000 with total prob : 99.95041656 \n",
      "391.7777898311615\n",
      "validation loss decreased , saving model (-0.99946021 ==> -0.99950414)\n",
      "Epoch 32 : Training loss 0.00019908 and valid loss : -0.99954129 :  \n",
      "Epoch 32 : valid accuracy :100.00000000 with total prob : 99.95413208 \n",
      "393.39807772636414\n",
      "validation loss decreased , saving model (-0.99950414 ==> -0.99954129)\n",
      "Epoch 33 : Training loss 0.00018221 and valid loss : -0.99957300 :  \n",
      "Epoch 33 : valid accuracy :100.00000000 with total prob : 99.95730591 \n",
      "393.2243709564209\n",
      "validation loss decreased , saving model (-0.99954129 ==> -0.99957300)\n",
      "Epoch 34 : Training loss 0.00016758 and valid loss : -0.99960032 :  \n",
      "Epoch 34 : valid accuracy :100.00000000 with total prob : 99.96003723 \n",
      "395.60269045829773\n",
      "validation loss decreased , saving model (-0.99957300 ==> -0.99960032)\n",
      "Epoch 35 : Training loss 0.00015479 and valid loss : -0.99962404 :  \n",
      "Epoch 35 : valid accuracy :100.00000000 with total prob : 99.96240997 \n",
      "391.45888018608093\n",
      "validation loss decreased , saving model (-0.99960032 ==> -0.99962404)\n",
      "Epoch 36 : Training loss 0.00014352 and valid loss : -0.99964481 :  \n",
      "Epoch 36 : valid accuracy :100.00000000 with total prob : 99.96448517 \n",
      "392.2147648334503\n",
      "validation loss decreased , saving model (-0.99962404 ==> -0.99964481)\n",
      "Epoch 37 : Training loss 0.00013352 and valid loss : -0.99966312 :  \n",
      "Epoch 37 : valid accuracy :100.00000000 with total prob : 99.96631622 \n",
      "391.995774269104\n",
      "validation loss decreased , saving model (-0.99964481 ==> -0.99966312)\n",
      "Epoch 38 : Training loss 0.00012459 and valid loss : -0.99967938 :  \n",
      "Epoch 38 : valid accuracy :100.00000000 with total prob : 99.96794128 \n",
      "395.71716833114624\n",
      "validation loss decreased , saving model (-0.99966312 ==> -0.99967938)\n",
      "Epoch 39 : Training loss 0.00011659 and valid loss : -0.99969391 :  \n",
      "Epoch 39 : valid accuracy :100.00000000 with total prob : 99.96939087 \n",
      "401.6333210468292\n",
      "validation loss decreased , saving model (-0.99967938 ==> -0.99969391)\n",
      "Epoch 40 : Training loss 0.00010939 and valid loss : -0.99970699 :  \n",
      "Epoch 40 : valid accuracy :100.00000000 with total prob : 99.97069550 \n",
      "403.2925775051117\n",
      "validation loss decreased , saving model (-0.99969391 ==> -0.99970699)\n",
      "Epoch 41 : Training loss 0.00010287 and valid loss : -0.99971884 :  \n",
      "Epoch 41 : valid accuracy :100.00000000 with total prob : 99.97187805 \n",
      "396.7552149295807\n",
      "validation loss decreased , saving model (-0.99970699 ==> -0.99971884)\n",
      "Epoch 42 : Training loss 0.00009695 and valid loss : -0.99972962 :  \n",
      "Epoch 42 : valid accuracy :100.00000000 with total prob : 99.97296906 \n",
      "398.2219512462616\n",
      "validation loss decreased , saving model (-0.99971884 ==> -0.99972962)\n",
      "Epoch 43 : Training loss 0.00009156 and valid loss : -0.99973949 :  \n",
      "Epoch 43 : valid accuracy :100.00000000 with total prob : 99.97395325 \n",
      "392.63967061042786\n",
      "validation loss decreased , saving model (-0.99972962 ==> -0.99973949)\n",
      "Epoch 44 : Training loss 0.00008663 and valid loss : -0.99974857 :  \n",
      "Epoch 44 : valid accuracy :100.00000000 with total prob : 99.97486115 \n",
      "398.2848541736603\n",
      "validation loss decreased , saving model (-0.99973949 ==> -0.99974857)\n",
      "Epoch 45 : Training loss 0.00008212 and valid loss : -0.99975695 :  \n",
      "Epoch 45 : valid accuracy :100.00000000 with total prob : 99.97570038 \n",
      "398.2059488296509\n",
      "validation loss decreased , saving model (-0.99974857 ==> -0.99975695)\n",
      "Epoch 46 : Training loss 0.00007797 and valid loss : -0.99976473 :  \n",
      "Epoch 46 : valid accuracy :100.00000000 with total prob : 99.97646332 \n",
      "399.4209985733032\n",
      "validation loss decreased , saving model (-0.99975695 ==> -0.99976473)\n",
      "Epoch 47 : Training loss 0.00007415 and valid loss : -0.99977198 :  \n",
      "Epoch 47 : valid accuracy :100.00000000 with total prob : 99.97720337 \n",
      "402.21263790130615\n",
      "validation loss decreased , saving model (-0.99976473 ==> -0.99977198)\n",
      "Epoch 48 : Training loss 0.00007062 and valid loss : -0.99977874 :  \n",
      "Epoch 48 : valid accuracy :100.00000000 with total prob : 99.97788239 \n",
      "402.823477268219\n",
      "validation loss decreased , saving model (-0.99977198 ==> -0.99977874)\n",
      "Epoch 49 : Training loss 0.00006735 and valid loss : -0.99978509 :  \n",
      "Epoch 49 : valid accuracy :100.00000000 with total prob : 99.97851562 \n",
      "391.6095287799835\n",
      "validation loss decreased , saving model (-0.99977874 ==> -0.99978509)\n",
      "19843.56312441826\n"
     ]
    }
   ],
   "source": [
    "#labels1=labels[loc]\n",
    "a=time.time()\n",
    "inputs=torch_tensor[:,:].to(device) \n",
    "labels1=labels[:].to(device)\n",
    "print(len(inputs))\n",
    "print(len(labels1))\n",
    "vinputs =vtorch_tensor[:,:].to(device)\n",
    "vlabels1=vlabels[:].to(device)\n",
    "\n",
    "epochs = 50\n",
    "valid_loss=0\n",
    "accuracy=0\n",
    "valid_loss_min=np.Inf\n",
    "\n",
    "####33  !!!!!!!!!! This shit cost alot of time ----> do not use it \n",
    "#b=time.time()\n",
    "#with torch.no_grad():\n",
    "   # for i, x in enumerate(vinputs):\n",
    "       # x2=x[None,:]\n",
    "       # output = torch.exp(model(x2))\n",
    "       # l2=vlabels1[i][None]\n",
    "       # test_loss+=Fonction_de_perte(output, l2)\n",
    "     #   output = torch.exp(output)\n",
    "      #  top_p , top_c = output.topk(1, dim=1)\n",
    "     #   equals = top_c==vlabels1[i].view(*top_c.shape)\n",
    "    #    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "   # tain_losses.append(running_loss/len(inputs))\n",
    "   # test_losses.append(test_loss/len(vinputs))\n",
    "   # print ('test accuracy :{0}, test loss : {2} ,  time {1} '.format(accuracy*100/len(vinputs) , time.time()-b ,test_loss/len(vinputs) ))\n",
    "\n",
    "######## ---> use this :) \n",
    "b=time.time()\n",
    "with torch.no_grad():\n",
    "    output = torch.exp(model(vinputs))\n",
    "    valid_loss=Fonction_de_perte(output, vlabels1)\n",
    "top_p , top_c = output.topk(1, dim=1)\n",
    "propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "equals = top_c==vlabels1.view(*top_c.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "#print ('valid accuracy :{0:.8f} with total prob : {3:.8f} and  valid loss : {2:.8f} ,  time {1:.6f} '.format(accuracy*100 , time.time()-b ,test_loss,propabilities))\n",
    "print ('Epoch  : valid accuracy :{0:.8f} with total prob : {1:.8f} '.format(accuracy*100  ,propabilities))\n",
    "\n",
    "####\n",
    "#print(inputs.shape[0])\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "for e in range(epochs):\n",
    "    c=time.time()\n",
    "    running_loss = 0\n",
    "    for i, x in enumerate(inputs):\n",
    "        optimizer.zero_grad()\n",
    "        x2=x[None,:]\n",
    "        output = model.forward(x2)\n",
    "        l2=labels1[i][None]\n",
    "        #print(l2)\n",
    "        loss = Fonction_de_perte(output, l2)\n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        accuracy=0\n",
    "        #print(l2)\n",
    "  \n",
    "        b=time.time()\n",
    "        with torch.no_grad():\n",
    "            ##\n",
    "            #with torch.no_grad():\n",
    "            #for i, x in enumerate(vinputs):\n",
    "             #   x2=x[None,:]\n",
    "              #  output = torch.exp(model(x2))\n",
    "               # l2=vlabels1[i][None]\n",
    "                #valid_loss1+=Fonction_de_perte(output, l2)\n",
    "            #test_loss=test_loss/len(vinputs)\n",
    "            ##\n",
    "                \n",
    "            model.eval()\n",
    "            output = torch.exp(model(vinputs))\n",
    "            valid_loss=Fonction_de_perte(output, vlabels1)\n",
    "        top_p , top_c = output.topk(1, dim=1)\n",
    "        propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "        equals = top_c==vlabels1.view(*top_c.shape)\n",
    "        accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        print('Epoch {2} : Training loss {0:.8f} and valid loss : {1:.8f} :  '.format(running_loss/len(inputs),valid_loss, e))\n",
    "   \n",
    "        print ('Epoch {2} : valid accuracy :{0:.8f} with total prob : {1:.8f} '.format(accuracy*100  ,propabilities, e))\n",
    "        print(time.time()-c)\n",
    "    #print('validation loss with iterations {0}'.format(valid_loss1/len(vinputs) ) )   \n",
    "        train_losses.append(running_loss/len(inputs))\n",
    "        valid_losses.append(valid_loss)\n",
    "        if (valid_loss<valid_loss_min):\n",
    "            print('validation loss decreased , saving model ({:.8f} ==> {:.8f})'.format(valid_loss_min,valid_loss))\n",
    "            torch.save(model.state_dict(),'mod_temp6_50_LSTM_B.pth')\n",
    "            valid_loss_min=valid_loss\n",
    "print(time.time()-a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T00:57:34.527035Z",
     "iopub.status.busy": "2021-08-23T00:57:34.526089Z",
     "iopub.status.idle": "2021-08-23T00:57:34.752157Z",
     "shell.execute_reply": "2021-08-23T00:57:34.752633Z"
    },
    "papermill": {
     "duration": 0.25296,
     "end_time": "2021-08-23T00:57:34.752807",
     "exception": false,
     "start_time": "2021-08-23T00:57:34.499847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff45908c9d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "#test_losses_scaled = scaler.fit_transform(test_losses)\n",
    "\n",
    "\n",
    "\n",
    "Tr=np.array(train_losses)\n",
    "Te=np.array(valid_losses)\n",
    "\n",
    "Tr=np.reshape(Tr, (len(Tr),1))\n",
    "Te=np.reshape(Te, (len(Te),1))\n",
    "\n",
    "# fit on training data column\n",
    "scale = StandardScaler().fit(Tr)\n",
    "tain_losses = scale.transform(Tr)\n",
    "scale = StandardScaler().fit(Te)\n",
    "test_losses = scale.transform(Te)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "#test_losses_scaled = scaler.fit_transform(test_losses)\n",
    "plt.ylim([-1,1])\n",
    "\n",
    "plt.plot(tain_losses, label='Train loss')\n",
    "plt.plot(test_losses, label='valid loss')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T00:57:34.830639Z",
     "iopub.status.busy": "2021-08-23T00:57:34.829816Z",
     "iopub.status.idle": "2021-08-23T00:59:49.233461Z",
     "shell.execute_reply": "2021-08-23T00:59:49.233998Z"
    },
    "papermill": {
     "duration": 134.456412,
     "end_time": "2021-08-23T00:59:49.234364",
     "exception": false,
     "start_time": "2021-08-23T00:57:34.777952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "test accuracy :99.98743439 with total prob : 99.92295074 and  test loss : -0.99919791 ,  time 4.69723773 \n",
      "la précision de detection globale: 99.91979139969845 \n",
      "detection des communication normal: 99.89184035 with accuracy 99.98551592 ( 103547/103562 )\n",
      "details normal classed udp :0.01448, pluies 0.00000 , jam 0.00000 (ou 100.00000,0.00000,0.00000) \n",
      "detection du deni de service par udp flood 99.99273800 with accuracy 99.99243990 ( 39679/39682 )\n",
      "details udp classed normal :0.00756, pluies 0.00000 , jam 0.00000 (ou 100.00000,0.00000,0.00000) \n",
      "=====================\n",
      "<================================>\n",
      "Total_time\n",
      "134.39867115020752\n"
     ]
    }
   ],
   "source": [
    "a=time.time()\n",
    "summm=[]\n",
    "sum1=[]\n",
    "sum2=[]\n",
    "sum3=[]\n",
    "sum4=[]\n",
    "\n",
    "tinputs =ttorch_tensor[:,:] \n",
    "tlabels1=tlabels[:]\n",
    "\n",
    "\n",
    "#tinputs =torch_tensor[:,:] \n",
    "#tlabels1=labels[:]\n",
    "\n",
    "print('=====================')\n",
    "b=time.time()\n",
    "output = torch.exp(model(tinputs))\n",
    "test_loss=Fonction_de_perte(output, tlabels1)\n",
    "top_p , top_c = output.topk(1, dim=1)\n",
    "propabilities= torch.mean(top_p.type(torch.FloatTensor))*100\n",
    "equals = top_c==tlabels1.view(*top_c.shape)\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "model.train()\n",
    "print ('test accuracy :{0:.8f} with total prob : {3:.8f} and  test loss : {2:.8f} ,  time {1:.8f} '.format(accuracy*100 , time.time()-b ,test_loss ,propabilities))\n",
    "class_correct = list(0. for i in range (4))\n",
    "class_total = list(0. for i in range (4))\n",
    "\n",
    "C_n_udp=0\n",
    "C_n_pluies=0\n",
    "C_n_jam=0\n",
    "C_n_total=0\n",
    "\n",
    "\n",
    "C_u_normal=0\n",
    "C_u_jam=0\n",
    "C_u_pluies=0\n",
    "C_u_total=0\n",
    "\n",
    "C_p_normal=0\n",
    "C_p_udp=0\n",
    "C_p_jam=0\n",
    "C_p_total=0\n",
    "\n",
    "C_j_normal=0\n",
    "C_j_udp=0\n",
    "C_j_pluies=0\n",
    "C_j_total=0\n",
    "\n",
    "for i, x in enumerate(tinputs):\n",
    "    optimizer.zero_grad()\n",
    "    x2=x[None,:]\n",
    "    with torch.no_grad():\n",
    "        output = torch.exp(model(x2))\n",
    "    out=output.detach().numpy()*100\n",
    " \n",
    "    l3=tlabels1[i].item()\n",
    "  \n",
    "    if(l3==0):\n",
    "        summm.append(out[0][0])\n",
    "        sum1.append(out[0][0])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_n_udp+=1\n",
    "            #if(top_c[i][0]==2):\n",
    "            #    C_n_pluies+=1\n",
    "            #if(top_c[i][0]==3):\n",
    "            #    C_n_jam +=1\n",
    "            \n",
    "            C_n_total +=1\n",
    "            \n",
    "    if(l3==1):\n",
    "        summm.append(out[0][1])\n",
    "        sum2.append(out[0][1])\n",
    "        if(top_c[i][0]!=l3):\n",
    "           # if(top_c[i][0]==3):\n",
    "            #    C_u_jam+=1\n",
    "           # if(top_c[i][0]==2):\n",
    "           #     C_u_pluies+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_u_normal +=1\n",
    "            \n",
    "            C_u_total +=1\n",
    "\n",
    "    if(l3==2):\n",
    "        summm.append(out[0][2])\n",
    "        sum3.append(out[0][2])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_p_udp+=1\n",
    "            if(top_c[i][0]==3):\n",
    "                C_p_jam+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_p_normal +=1\n",
    "            \n",
    "            C_p_total +=1\n",
    "\n",
    "    if(l3==3):\n",
    "        summm.append(out[0][3])\n",
    "        sum4.append(out[0][3])\n",
    "        if(top_c[i][0]!=l3):\n",
    "            if(top_c[i][0]==1):\n",
    "                C_j_udp+=1\n",
    "            if(top_c[i][0]==2):\n",
    "                C_j_pluies+=1\n",
    "            if(top_c[i][0]==0):\n",
    "                C_j_normal +=1\n",
    "            \n",
    "            C_j_total +=1\n",
    "\n",
    "    class_total[l3]+=1\n",
    "    class_correct[l3]+=equals[i][0]\n",
    "    #print(output)\n",
    "print('la précision de detection globale: {0} '.format(mean(summm)))\n",
    "print('detection des communication normal: {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum1), class_correct[0]*100/class_total[0] ,class_correct[0] ,class_total[0]))\n",
    "if(C_n_total!=0):\n",
    "    print('details normal classed udp :{0:.5f}, pluies {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_n_udp*100/class_total[0],C_n_pluies*100/class_total[0],C_n_jam*100/class_total[0],C_n_udp*100/C_n_total,C_n_pluies*100/C_n_total,C_n_jam*100/C_n_total))\n",
    "else:\n",
    "    print('detection normal 100')\n",
    "\n",
    "print('detection du deni de service par udp flood {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum2), class_correct[1]*100/class_total[1] ,class_correct[1] ,class_total[1]))\n",
    "if(C_u_total!=0):\n",
    "    print('details udp classed normal :{0:.5f}, pluies {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_u_normal*100/class_total[1],C_u_pluies*100/class_total[1],C_u_jam*100/class_total[1],C_u_normal*100/C_u_total,C_u_pluies*100/C_u_total,C_u_jam*100/C_u_total))\n",
    "else:\n",
    "    print('detection udp flood 100')\n",
    "    \n",
    "#print('detection du deni naturel : pluies et orages : {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum3), class_correct[2]*100/class_total[2] ,class_correct[2] ,class_total[2]))\n",
    "#if(C_p_total!=0):\n",
    "#    print('details pluies classed udp :{0:.5f}, normal {1:.5f} , jam {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_p_udp*100/class_total[2],C_p_normal*100/class_total[2],C_p_jam*100/class_total[2],C_p_udp*100/C_p_total,C_p_normal*100/C_p_total,C_p_jam*100/C_p_total))\n",
    "#else:\n",
    " #   print('detection pluies et orages 100')\n",
    "\n",
    "#print('detection du deni naturel : jam : {0:.8f} with accuracy {1:.8f} ( {2:.0f}/{3:.0f} )'.format(mean(sum4), class_correct[3]*100/class_total[3] ,class_correct[3] ,class_total[3]))\n",
    "#if(C_j_total!=0):\n",
    "#    print('details jam classed udp :{0:.5f}, pluies {1:.5f} , normal {2:.5f} (ou {3:.5f},{4:.5f},{5:.5f}) '.format(C_j_udp*100/class_total[3],C_j_pluies*100/class_total[3],C_j_normal*100/class_total[3],C_j_udp*100/C_j_total,C_j_pluies*100/C_j_total,C_j_normal*100/C_j_total))\n",
    "#else:\n",
    "#    print('detection brouillage 100')\n",
    "print('=====================')\n",
    "\n",
    "print('<================================>')\n",
    "print('Total_time')\n",
    "print(time.time()-a)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19999.446195,
   "end_time": "2021-08-23T00:59:51.058635",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-22T19:26:31.612440",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
